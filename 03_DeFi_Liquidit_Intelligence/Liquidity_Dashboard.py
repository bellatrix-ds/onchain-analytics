import streamlit as st
import pandas as pd
import plotly.graph_objects as go
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
from matplotlib.dates import DateFormatter
import numpy as np
import altair as alt
from sklearn.preprocessing import MinMaxScaler
import requests
import json
import google.generativeai as genai
from together import Together
# __________________ Import Data ______________________________________________________________________

data = pd.read_csv('https://raw.githubusercontent.com/bellatrix-ds/onchain-analytics/refs/heads/main/03_DeFi_Liquidit_Intelligence/df_main.csv', on_bad_lines='skip')

st.title("ğŸ” Pool Liquidity Intelligence")
st.set_page_config(layout="wide")

# __________________ Filters ______________________________________________________________________


col1, col2, col3 = st.columns(3)
with col1:
    selected_protocol = st.selectbox("Lending Protocol", options=data['lending_protocol'].dropna().unique())
with col2:
    selected_chain = st.selectbox("Chain", options=data[data['lending_protocol'] == selected_protocol]['chain'].dropna().unique())
with col3:
    selected_pool = st.selectbox("Pool", options=data[(data['lending_protocol'] == selected_protocol) & (data['chain'] == selected_chain)]['pool'].dropna().unique())

filtered_data = data[
    (data['lending_protocol'] == selected_protocol) &
    (data['chain'] == selected_chain) &
    (data['pool'] == selected_pool)
].copy()

#filtered_data['block_timestamp'] = pd.to_datetime(filtered_data['block_timestamp'], errors='coerce')
st.markdown("___")
# __________________ Part 1: Trends ______________________________________________________________________

col4, col5 = st.columns(2)

with col4:
    st.subheader("Utilization Rate Over Time")
    fig = px.line(
        filtered_data,
        x='block_timestamp',
        y='utilization_rate',
        markers=True,
        labels={'block_timestamp': 'Date', 'utilization_rate': 'Utilization Rate'}
    )
    st.plotly_chart(fig, use_container_width=True)

with col5:
    st.markdown("### ğŸ”„ Net Flow ÛŒØ¹Ù†ÛŒ Ú†Ù‡ØŸ")
    st.write("""
    Ø§ÛŒÙ† Ù†Ù…ÙˆØ¯Ø§Ø± Ù…ÛŒØ²Ø§Ù† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù†Ù‚Ø¯ÛŒÙ†Ú¯ÛŒ Ø±Ø§ Ø¯Ø± Ø·ÙˆÙ„ Ø²Ù…Ø§Ù† Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªØ®Ø± Ø§Ù†ØªØ®Ø§Ø¨â€ŒØ´Ø¯Ù‡ Ù†Ø´Ø§Ù† Ù…ÛŒâ€ŒØ¯Ù‡Ø¯.  
    **Ø¨Ø§Ù„Ø§** Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ù†Ø´Ø§Ù†Ù‡ ÙØ´Ø§Ø± Ù†Ù‚Ø¯ÛŒÙ†Ú¯ÛŒ Ø¨Ø§Ø´Ø¯. Ø¯Ø± Ø­Ø§Ù„ÛŒ Ú©Ù‡ Ù†Ø±Ø® **Ù¾Ø§ÛŒÛŒÙ†** Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¨Ù‡ Ù…Ø¹Ù†ÛŒ Ø³Ø±Ù…Ø§ÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø¨Ù„Ø§Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¨Ø§Ø´Ø¯.  
    Ù†Ù‚Ø§Ø· **ØµÙØ±** ÛŒØ§ **Ù†Ø§Ù„** Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Ø¨Ù‡ Ù…Ø¹Ù†ÛŒ ÙÙ‚Ø¯Ø§Ù† ÙØ¹Ø§Ù„ÛŒØª ÛŒØ§ Ø«Ø¨Øªâ€ŒÙ†Ø´Ø¯Ù† Ø¯Ø§Ø¯Ù‡ Ø¯Ø± Ø¢Ù† Ø±ÙˆØ² Ø®Ø§Øµ Ù‡Ø³ØªÙ†Ø¯.
    """)

st.markdown("___")
# __________________ Part 2: Net Flow ______________________________________________________________________

import streamlit as st
import pandas as pd
import requests
import json
import plotly.express as px

# ğŸ”§ Load the filtered Net Flow data
df_netflow = filtered_data[['block_timestamp', 'net_flow']].dropna()
df_netflow['block_timestamp'] = pd.to_datetime(df_netflow['block_timestamp'])

# ğŸ“Š Net Flow Chart (left column)
col1, col2 = st.columns([1, 1.1])
with col1:
    st.markdown("### ğŸ“ˆ Net Flow Over Time")
    fig = px.area(df_netflow, x='block_timestamp', y='net_flow',
                  color_discrete_sequence=['#2196F3'], height=400)
    fig.update_layout(xaxis_title='Date', yaxis_title='Net Flow')
    st.plotly_chart(fig, use_container_width=True)

# ğŸ§  AI Analysis Prompt Selector (right column)
with col2:
    st.markdown("### ğŸ¤– AI-Powered Summary")
    analysis_type = st.selectbox("Select the type of analysis you want:", [
        "ğŸ” Key insights (3 bullets)",
        "âš ï¸ Risks and outflow alerts",
        "ğŸ“ˆ Trend & volatility explanation",
        "ğŸ§  Full narrative analysis"
    ])

    # Context: convert time series to plain text summary
    def make_context(df):
        context = ""
        for _, row in df.sort_values('block_timestamp').iterrows():
            date = row['block_timestamp'].strftime('%Y-%m-%d')
            context += f"{date}: {row['net_flow']:.2f}\n"
        return context.strip()

    context_text = make_context(df_netflow)

    # Prompt based on analysis type
    prompt_map = {
        "ğŸ” Key insights (3 bullets)": "Give exactly 3 non-obvious insights from the Net Flow time series. Do not explain what net flow is.",
        "âš ï¸ Risks and outflow alerts": "Analyze the net flow data and highlight any potential risks, large withdrawals, or warning signs in under 5 bullet points.",
        "ğŸ“ˆ Trend & volatility explanation": "Explain the trends and volatility of the Net Flow values over time. Be concise and skip basic definitions.",
        "ğŸ§  Full narrative analysis": "Provide a full analytical narrative of the Net Flow behavior in this DeFi lending pool. Include major changes and possible causes."
    }
    prompt = prompt_map[analysis_type]

    # ğŸ”‘ Together API config
    TOGETHER_API_URL = "https://api.together.xyz/v1/chat/completions"
    TOGETHER_API_KEY = st.secrets["TOGETHER_API_KEY"]

    def ask_ai(prompt, context):
        headers = {
            "Authorization": f"Bearer {TOGETHER_API_KEY}",
            "Content-Type": "application/json"
        }
        payload = {
            "model": "Qwen/QwQ-32B",
            "messages": [
                {"role": "system", "content": "You are a DeFi data analyst."},
                {"role": "user", "content": f"Context:\n{context}"},
                {"role": "user", "content": prompt}
            ],
            "temperature": 0.7,
            "top_p": 0.9,
            "max_tokens": 1024
        }
        response = requests.post(TOGETHER_API_URL, headers=headers, json=payload)
        if response.ok:
            return response.json()["choices"][0]["message"]["content"]
        else:
            raise Exception(f"âŒ API Error: {response.status_code}, {response.text}")

    # ğŸ” Run AI Analysis
    with st.spinner("Analyzing Net Flow using AI..."):
        try:
            output = ask_ai(prompt, context_text)
            st.markdown("### âœ… AI Analysis")
            for line in output.strip().split("\n"):
                if line.strip().startswith("-") or line.strip().startswith("â€¢"):
                    st.markdown(f"{line.strip()}")
        except Exception as e:
            st.error(f"âŒ AI Analysis failed: {e}")


st.markdown("___")
